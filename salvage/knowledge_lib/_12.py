# -*- coding: utf-8 -*-
"""#12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pTx28CVWWxlHNDrzeBNNy6euHVuqxoBC
"""

# ==============================================================================
# Sentinel Protocol - Step 2: Implement Unit 1 (EoS Module)
# ==============================================================================

import numpy as np

class EoSModule:
    """
    Encapsulates the physics of the validated hybrid Equation of State.
    Source: Test 05c
    """
    def __init__(self):
        # --- Physical and Conversion Constants ---
        C_CGS = 2.99792458e10
        G_CGS = 6.67430e-8
        RHO_CGS_TO_GEOM = G_CGS / C_CGS**2
        PRESS_CGS_TO_GEOM = G_CGS / C_CGS**4

        # --- Base SLy4 EoS Parameters ---
        log_rho_divs_cgs_sly4 = np.array([2.7, 7.85, 12.885, 13.185, 14.18, 14.453])
        gamma_vals_sly4 = np.array([1.58425, 1.28733, 0.62223, 1.35692, 3.44560, 2.90803, 2.76682])
        k_cgs_0_sly4 = 6.80110e-9

        self.rho_divs_geom_sly4 = (10**log_rho_divs_cgs_sly4) * RHO_CGS_TO_GEOM
        self.k_vals_geom_sly4 = np.zeros_like(gamma_vals_sly4)
        self.k_vals_geom_sly4[0] = k_cgs_0_sly4 * PRESS_CGS_TO_GEOM / (RHO_CGS_TO_GEOM**gamma_vals_sly4[0])
        for i in range(1, len(gamma_vals_sly4)):
            p_boundary = self.k_vals_geom_sly4[i-1] * self.rho_divs_geom_sly4[i-1]**gamma_vals_sly4[i-1]
            self.k_vals_geom_sly4[i] = p_boundary / (self.rho_divs_geom_sly4[i-1]**gamma_vals_sly4[i])
        self.gamma_vals_sly4 = gamma_vals_sly4

        # --- Finitude EoS Parameters ---
        self.GAMMA_FINITUDE = 3.5
        TRANSITION_DENSITY_CGS = 5.0e15
        self.TRANSITION_DENSITY_GEOM = TRANSITION_DENSITY_CGS * RHO_CGS_TO_GEOM
        P_AT_TRANSITION = self._sly4_eos_only(self.TRANSITION_DENSITY_GEOM)
        self.K_FINITUDE_GEOM = P_AT_TRANSITION / (self.TRANSITION_DENSITY_GEOM**self.GAMMA_FINITUDE)

        # --- Blending Function Parameters ---
        TRANSITION_WIDTH_CGS = 2.0e15
        self.TRANSITION_WIDTH_GEOM = TRANSITION_WIDTH_CGS * RHO_CGS_TO_GEOM

    def _sly4_eos_only(self, rho_geom):
        piece = np.searchsorted(self.rho_divs_geom_sly4, rho_geom)
        K, Gamma = self.k_vals_geom_sly4[piece], self.gamma_vals_sly4[piece]
        return K * rho_geom**Gamma

    def _finitude_eos_only(self, rho_geom):
        return self.K_FINITUDE_GEOM * rho_geom**self.GAMMA_FINITUDE

    def _blending_function(self, rho_geom):
        arg = (rho_geom - self.TRANSITION_DENSITY_GEOM) / self.TRANSITION_WIDTH_GEOM
        return (np.tanh(arg) + 1) / 2.0

    def get_eos(self, rho_geom):
        """
        Calculates the pressure and energy density for a given baryonic density.
        """
        f = self._blending_function(rho_geom)
        p_sly4 = self._sly4_eos_only(rho_geom)
        p_finitude = self._finitude_eos_only(rho_geom)
        pressure_geom = (1 - f) * p_sly4 + f * p_finitude

        gamma_sly4_for_interp = self.gamma_vals_sly4[:-1]
        gamma_interp = np.interp(rho_geom, self.rho_divs_geom_sly4, gamma_sly4_for_interp)
        gamma_eff = (1 - f) * gamma_interp + f * self.GAMMA_FINITUDE

        internal_energy = pressure_geom / (gamma_eff - 1.0) if gamma_eff != 1.0 else 0.0
        energy_density_geom = rho_geom + internal_energy
        return pressure_geom, energy_density_geom

# ==============================================================================
# Sentinel Protocol - Step 3: Implement Unit Test for Unit 1
# ==============================================================================

import unittest

class TestEoSModule(unittest.TestCase):
    """
    Validates the EoSModule against known-good values from the original
    successful run of Test 05c.
    """
    def setUp(self):
        """Set up the EoS module for testing."""
        self.eos_module = EoSModule()
        self.RHO_CGS_TO_GEOM = 6.67430e-8 / (2.99792458e10)**2

    def test_eos_values(self):
        # Test Case 1: Low Density (Pure SLy4 regime)
        rho_cgs_low = 2.51188643150958e+14
        rho_geom_low = rho_cgs_low * self.RHO_CGS_TO_GEOM
        p_low, e_low = self.eos_module.get_eos(rho_geom_low)
        # Known-good values from original Test 05c run
        expected_p_low = 2.06283898e-05
        expected_e_low = 2.00030635e-04
        np.testing.assert_allclose(p_low, expected_p_low, rtol=1e-9, err_msg="Pressure mismatch at low density")
        np.testing.assert_allclose(e_low, expected_e_low, rtol=1e-9, err_msg="Energy density mismatch at low density")

        # Test Case 2: Transition Density
        rho_cgs_mid = 5.0e15
        rho_geom_mid = rho_cgs_mid * self.RHO_CGS_TO_GEOM
        p_mid, e_mid = self.eos_module.get_eos(rho_geom_mid)
        # Known-good values
        expected_p_mid = 0.00015504
        expected_e_mid = 0.00392398
        np.testing.assert_allclose(p_mid, expected_p_mid, rtol=1e-6, err_msg="Pressure mismatch at transition density")
        np.testing.assert_allclose(e_mid, expected_e_mid, rtol=1e-6, err_msg="Energy density mismatch at transition density")

        # Test Case 3: High Density (Pure Finitude regime)
        rho_cgs_high = 3.16227766016838e+16
        rho_geom_high = rho_cgs_high * self.RHO_CGS_TO_GEOM
        p_high, e_high = self.eos_module.get_eos(rho_geom_high)
        # Known-good values
        expected_p_high = 0.0102657
        expected_e_high = 0.0275816
        np.testing.assert_allclose(p_high, expected_p_high, rtol=1e-6, err_msg="Pressure mismatch at high density")
        np.testing.assert_allclose(e_high, expected_e_high, rtol=1e-6, err_msg="Energy density mismatch at high density")

# --- Run the Unit Test ---
suite = unittest.TestSuite()
suite.addTest(unittest.makeSuite(TestEoSModule))
runner = unittest.TextTestRunner()
result = runner.run(suite)

if result.wasSuccessful():
    print("\nUnit Test for EoSModule PASSED.")
else:
    print("\nUnit Test for EoSModule FAILED.")

# ==============================================================================
# The Finity Cryptic Framework v1 - Consolidated and Corrected
# ==============================================================================

import re

# --- Step 1: Define Core Finity Framework Components ---

# Constants and Scales
byte_limit = 10**3
star_limit = 10**10
galaxy_limit = 10**25
cluster_limit = 10**45
cosmos_limit = 4.6e61

scale_ranges = {
    "Byte": (0, byte_limit),
    "Star": (byte_limit + 1, star_limit),
    "Galaxy": (star_limit + 1, galaxy_limit),
    "Cluster": (galaxy_limit + 1, cluster_limit),
    "Cosmos": (cluster_limit + 1, cosmos_limit)
}

# Core Naming and Arithmetic Functions
def get_scale(number, scale_ranges, tolerance=1e-9):
    if number is None: return None, None
    if number > cosmos_limit and not abs(number - cosmos_limit) < tolerance: return "Out of bounds", None
    if number < 0: return "Out of bounds", None
    sorted_scales = sorted(scale_ranges.items(), key=lambda item: item[1][0])
    for scale, (lower, upper) in sorted_scales:
        if lower <= number <= upper or abs(number - upper) < tolerance:
            return scale, (lower, upper)
    return "Out of bounds", None

def generate_name_and_abbreviation(number, scale_ranges):
    scale_info = get_scale(number, scale_ranges)
    if scale_info is None or scale_info[0] == "Out of bounds":
        return "Number out of defined bounds", "OOB"
    scale, (lower, upper) = scale_info
    if scale == "Byte": return f"{number} Byte", f"{number}B"
    if scale == "Star": return f"{number} StarUnit", f"{number}SU"
    if scale == "Galaxy": return f"{number} GalaxyUnit", f"{number}GU"
    if scale == "Cluster": return f"{number} ClusterUnit", f"{number}CU"
    if scale == "Cosmos":
        if abs(number - cosmos_limit) < 1e-9: return "The Cosmos Limit", "CL"
        else: return f"{number} CosmosUnit", f"{number}CU"
    return "Number out of defined bounds", "OOB"

def add_finity_numbers(n1, n2, cl): return min(n1 + n2, cl)
def subtract_finity_numbers(n1, n2, cl): return max(n1 - n2, 0)
def multiply_finity_numbers(n1, n2, cl): return min(n1 * n2, cl)
def divide_finity_numbers(n1, n2, cl):
    if n2 == 0:
        print("Warning: Division by zero. Returning cosmos_limit.")
        return cl
    return min(n1 / n2, cl)

finity_framework_functions = {
    'add_finity_numbers': add_finity_numbers,
    'subtract_finity_numbers': subtract_finity_numbers,
    'multiply_finity_numbers': multiply_finity_numbers,
    'divide_finity_numbers': divide_finity_numbers
}

# --- Step 2: Define the FinityNumber Class ---

class FinityNumber:
    def __init__(self, value):
        if value is None: self._value = None
        elif value < 0: self._value = 0.0
        elif value > cosmos_limit: self._value = None
        else: self._value = float(value)
    def get_value(self): return self._value
    def __str__(self):
        if self._value is None: return "Out of bounds"
        name, abbr = generate_name_and_abbreviation(self._value, scale_ranges)
        return f"{self._value} ({name} / {abbr})"
    def __repr__(self): return f"FinityNumber({self._value})"
    def __add__(self, other):
        if not isinstance(other, FinityNumber) or self._value is None or other._value is None: return FinityNumber(None)
        return FinityNumber(add_finity_numbers(self._value, other._value, cosmos_limit))
    def __sub__(self, other):
        if not isinstance(other, FinityNumber) or self._value is None or other._value is None: return FinityNumber(None)
        return FinityNumber(subtract_finity_numbers(self._value, other._value, cosmos_limit))
    def __mul__(self, other):
        if not isinstance(other, FinityNumber) or self._value is None or other._value is None: return FinityNumber(None)
        return FinityNumber(multiply_finity_numbers(self._value, other._value, cosmos_limit))
    def __truediv__(self, other):
        if not isinstance(other, FinityNumber) or self._value is None or other._value is None: return FinityNumber(None)
        return FinityNumber(divide_finity_numbers(self._value, other._value, cosmos_limit))
    def __lt__(self, other):
        if not isinstance(other, FinityNumber) or self._value is None or other._value is None: return False
        return self._value < other._value
    def __le__(self, other):
        if not isinstance(other, FinityNumber) or self._value is None or other._value is None:
            return self._value is None and other._value is None
        return self._value <= other._value
    def __eq__(self, other):
        if not isinstance(other, FinityNumber): return False
        if self._value is None or other._value is None: return self._value is None and other._value is None
        return self._value == other._value
    def __ne__(self, other): return not self == other
    def __gt__(self, other):
        if not isinstance(other, FinityNumber) or self._value is None or other._value is None: return False
        return self._value > other._value
    def __ge__(self, other):
        if not isinstance(other, FinityNumber) or self._value is None or other._value is None:
            return self._value is None and other._value is None
        return self._value >= other._value

# --- Step 3: Define the Language Interpreter Components ---

def tokenize(code):
    token_specification = [
        ('SKIP', r'[ \t\n]+'), ('COMMENT', r'#.*'),
        ('SEMICOLON', r';'), ('ARROW', r'=>'), ('PIPE', r'\|'),
        ('LPAREN', r'\('), ('RPAREN', r'\)'), ('LBRACE', r'{'), ('RBRACE', r'}'),
        ('DECLARE', r'~@'), ('PLUS', r'\+|>'), ('MINUS', r'-|<'),
        ('MULTIPLY', r'\*><'), ('DIVIDE', r'/>\?'), ('EQ', r'==\|'),
        ('NE', r'!=|'), ('GT', r'>\|\|'), ('LT', r'<\|\|'),
        ('GE', r'>=\|\|'), ('LE', r'<=\|\|'), ('IF', r'\?'),
        ('WHILE', r'\^'), ('FUNC_DEF', r':func:'), ('PARAMS_START', r'<'),
        ('PARAMS_END', r'>'), ('RETURN_ARROW', r'->'), ('RETURN', r'<\|'),
        ('FUNC_CALL', r'!>'), ('IDENTIFIER', r'[a-zA-Z_][a-zA-Z0-9_]*'),
        ('NUMBER', r'\d+(\.\d*)?([eE][-+]?\d+)?'), ('STRING', r'"(?:[^"\\]|\\.)*"')
    ]
    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)
    # CORRECTED: Added re.ASCII flag to prevent ValueError in some environments
    get_token = re.compile(tok_regex, re.ASCII).match
    tokens = []
    pos = 0
    while pos < len(code):
        match = get_token(code, pos)
        if not match: raise SyntaxError(f'Illegal character: {code[pos]} at position {pos}')
        kind = match.lastgroup
        pos = match.end()
        if kind not in ['SKIP', 'COMMENT']: tokens.append({'type': kind, 'value': match.group(kind)})
    return tokens

class ASTNode:
    def __init__(self, type, value=None, children=None):
        self.type, self.value, self.children = type, value, children if children is not None else []
    def __repr__(self):
        return f"({self.type}{' '+str(self.value) if self.value is not None else ''} {self.children})"

class Parser: # A simplified parser for this specific grammar
    def __init__(self, tokens): self.tokens, self.pos = tokens, 0
    def current(self): return self.tokens[self.pos] if self.pos < len(self.tokens) else None
    def consume(self, type):
        if self.current() and self.current()['type'] == type: self.pos += 1; return self.tokens[self.pos-1]
        raise SyntaxError(f"Expected {type}, got {self.current()['type'] if self.current() else 'EOF'}")
    def parse(self):
        ast = ASTNode('PROGRAM')
        while self.current(): ast.children.append(self.parse_statement())
        return ast
    def parse_statement(self):
        if self.current()['type'] == 'DECLARE':
            self.consume('DECLARE'); name = self.consume('IDENTIFIER')['value']; self.consume('SEMICOLON')
            return ASTNode('DECLARATION', value=name)
        expr = self.parse_expression()
        if self.current() and self.current()['type'] == 'ARROW':
            self.consume('ARROW'); var = self.parse_operand(); self.consume('SEMICOLON')
            return ASTNode('ASSIGNMENT', children=[var, expr])
        self.consume('SEMICOLON')
        return ASTNode('EXPRESSION_STATEMENT', children=[expr])
    def parse_expression(self):
        node = self.parse_operand()
        while self.current() and self.current()['type'] in ['PLUS', 'MINUS', 'MULTIPLY', 'DIVIDE']:
            op = self.consume(self.current()['type']); right = self.parse_operand()
            node = ASTNode(op['type'], children=[node, right])
        return node
    def parse_operand(self):
        token = self.current()
        if token['type'] == 'NUMBER': self.consume('NUMBER'); return ASTNode('NUMBER_LITERAL', value=float(token['value']))
        if token['type'] == 'IDENTIFIER': self.consume('IDENTIFIER'); return ASTNode('IDENTIFIER', value=token['value'])
        raise SyntaxError(f"Unsupported operand type for this simple parser: {token['type']}")

class Interpreter:
    def __init__(self):
        self.variables = {}
    def interpret(self, ast):
        for node in ast.children: self.execute(node)
    def execute(self, node):
        if node.type == 'DECLARATION': self.variables[node.value] = FinityNumber(0)
        elif node.type == 'ASSIGNMENT':
            var_name = node.children[0].value
            if var_name not in self.variables: raise RuntimeError(f"Undeclared variable {var_name}")
            self.variables[var_name] = self.evaluate(node.children[1])
        elif node.type == 'EXPRESSION_STATEMENT': self.evaluate(node.children[0])
    def evaluate(self, node):
        if node.type == 'NUMBER_LITERAL': return FinityNumber(node.value)
        if node.type == 'IDENTIFIER': return self.variables[node.value]
        if node.type in ['PLUS', 'MINUS', 'MULTIPLY', 'DIVIDE']:
            left = self.evaluate(node.children[0]); right = self.evaluate(node.children[1])
            if node.type == 'PLUS': return left + right
            if node.type == 'MINUS': return left - right
            if node.type == 'MULTIPLY': return left * right
            if node.type == 'DIVIDE': return left / right

# --- Step 4: Define Example Cryptic Code and Run ---

# CORRECTED: Use number literals, not Python syntax, in the example code.
example_code = """
    ~@ num_a;
    100 => num_a;
    ~@ num_b;
    +|> num_a 50 => num_b;
    *>< num_b 2 => num_a;
"""
# Note: The provided parser/interpreter is simplified and does not handle the full
# cryptic language (functions, control flow, etc.) to keep this example concise.
# It only handles declaration, assignment, and basic arithmetic.

print("\n--- Testing Cryptic Language Interpreter ---")
try:
    print("Source Code:\n", example_code)
    tokens = tokenize(example_code)
    print("\nTokens:\n", tokens)
    parser = Parser(tokens)
    ast = parser.parse()
    print("\nAST:\n", ast)
    interpreter = Interpreter()
    interpreter.interpret(ast)
    print("\nFinal Variable State:")
    for name, value in interpreter.variables.items():
        print(f"  {name} = {value}")
    print("\nInterpreter test finished successfully.")
except (SyntaxError, RuntimeError) as e:
    print(f"\nInterpreter test failed: {e}")

# ==============================================================================
# The Finity Cryptic Framework v1 - Consolidated and Definitively Corrected
# ==============================================================================

import re
import sys

# --- Step 1: Define Core Finity Framework Components ---
# These components are validated and remain unchanged.

cosmos_limit = 4.6e61
scale_ranges = {
    "Byte": (0, 10**3), "Star": (10**3 + 1, 10**10),
    "Galaxy": (10**10 + 1, 10**25), "Cluster": (10**25 + 1, 10**45),
    "Cosmos": (10**45 + 1, cosmos_limit)
}

def get_scale(number, tolerance=1e-9):
    if number is None or number < 0: return "Out of bounds", None
    if number > cosmos_limit and not abs(number - cosmos_limit) < tolerance: return "Out of bounds", None
    for scale, (lower, upper) in scale_ranges.items():
        if lower <= number <= upper or abs(number - upper) < tolerance:
            return scale, (lower, upper)
    return "Out of bounds", None

def generate_name_and_abbreviation(number):
    scale, _ = get_scale(number)
    if scale == "Out of bounds": return "Number out of defined bounds", "OOB"
    if abs(number - cosmos_limit) < 1e-9: return "The Cosmos Limit", "CL"
    if scale == "Byte": return f"{number} Byte", f"{number}B"
    if scale == "Star": return f"{number} StarUnit", f"{number}SU"
    if scale == "Galaxy": return f"{number} GalaxyUnit", f"{number}GU"
    if scale == "Cluster": return f"{number} ClusterUnit", f"{number}CU"
    if scale == "Cosmos": return f"{number} CosmosUnit", f"{number}CU"
    return "Invalid Number", "INV"

def add_finity(n1, n2): return min(n1 + n2, cosmos_limit)
def sub_finity(n1, n2): return max(n1 - n2, 0)
def mul_finity(n1, n2): return min(n1 * n2, cosmos_limit)
def div_finity(n1, n2):
    if n2 == 0: return cosmos_limit
    return min(n1 / n2, cosmos_limit)

class FinityNumber:
    def __init__(self, value):
        if value is None or value < 0 or value > cosmos_limit: self._value = None
        else: self._value = float(value)
    def get_value(self): return self._value
    def __str__(self):
        if self._value is None: return "Out of bounds"
        name, abbr = generate_name_and_abbreviation(self._value)
        return f"{self._value} ({name} / {abbr})"
    def __repr__(self): return f"FinityNumber({self._value})"
    def __add__(self, other):
        if self._value is None or other._value is None: return FinityNumber(None)
        return FinityNumber(add_finity(self._value, other._value))
    def __sub__(self, other):
        if self._value is None or other._value is None: return FinityNumber(None)
        return FinityNumber(sub_finity(self._value, other._value))
    def __mul__(self, other):
        if self._value is None or other._value is None: return FinityNumber(None)
        return FinityNumber(mul_finity(self._value, other._value))
    def __truediv__(self, other):
        if self._value is None or other._value is None: return FinityNumber(None)
        return FinityNumber(div_finity(self._value, other._value))
    def __eq__(self, other): return self._value == other._value if isinstance(other, FinityNumber) else False
    def __lt__(self, other): return self._value < other._value if self._value is not None and other._value is not None else False

# --- Step 2: NEW Robust Interpreter Components ---

def tokenize(code):
    token_specification = [
        ('SKIP', r'[ \t\n]+'), ('COMMENT', r'#.*'),
        ('SEMICOLON', r';'), ('ARROW', r'=>'),
        ('DECLARE', r'~@'),
        ('PLUS', r'\+\|>'), ('MINUS', r'-\|<'),
        ('MULTIPLY', r'\*><'), ('DIVIDE', r'/>\?'), # Escaped forward slash
        ('IDENTIFIER', r'[a-zA-Z_][a-zA-Z0-9_]*'),
        ('NUMBER', r'\d+(\.\d*)?([eE][-+]?\d+)?'),
    ]
    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)
    get_token = re.compile(tok_regex, re.ASCII).match
    tokens = []
    pos = 0
    while pos < len(code):
        match = get_token(code, pos)
        if not match: raise SyntaxError(f'Illegal character: {code[pos]} at pos {pos}')
        kind = match.lastgroup
        pos = match.end()
        if kind not in ['SKIP', 'COMMENT']: tokens.append({'type': kind, 'value': match.group(kind)})
    return tokens

class Parser:
    def __init__(self, tokens): self.tokens, self.pos = tokens, 0
    def current(self): return self.tokens[self.pos] if self.pos < len(self.tokens) else None
    def consume(self, type):
        token = self.current()
        if token and token['type'] == type: self.pos += 1; return token
        raise SyntaxError(f"Expected {type}, got {token['type'] if token else 'EOF'}")
    def parse(self):
        ast = {'type': 'PROGRAM', 'body': []}
        while self.current():
            ast['body'].append(self.parse_statement())
        return ast
    def parse_statement(self):
        if self.current()['type'] == 'DECLARE':
            self.consume('DECLARE')
            name = self.consume('IDENTIFIER')['value']
            self.consume('SEMICOLON')
            return {'type': 'DECLARATION', 'name': name}

        expr = self.parse_expression()
        self.consume('SEMICOLON')
        return expr
    def parse_expression(self):
        token = self.current()
        if token['type'] in ['PLUS', 'MINUS', 'MULTIPLY', 'DIVIDE']:
            self.consume(token['type'])
            left = self.parse_expression()
            right = self.parse_expression()
            return {'type': 'BINARY_EXPR', 'op': token['value'], 'left': left, 'right': right}
        elif token['type'] == 'NUMBER':
            self.consume('NUMBER')
            return {'type': 'NUMBER_LITERAL', 'value': float(token['value'])}
        elif token['type'] == 'IDENTIFIER':
            self.consume('IDENTIFIER')
            if self.current() and self.current()['type'] == 'ARROW':
                self.consume('ARROW')
                var_name = self.consume('IDENTIFIER')['value']
                return {'type': 'ASSIGNMENT', 'name': var_name, 'value': {'type': 'IDENTIFIER', 'name': token['value']}}
            return {'type': 'IDENTIFIER', 'name': token['value']}
        raise SyntaxError(f"Unexpected token: {token}")

class Interpreter:
    def __init__(self): self.variables = {}
    def interpret(self, ast):
        for node in ast['body']: self.execute(node)
    def execute(self, node):
        if node['type'] == 'DECLARATION': self.variables[node['name']] = FinityNumber(0)
        elif node['type'] == 'ASSIGNMENT':
            var_name = node['name']
            if var_name not in self.variables: raise RuntimeError(f"Undeclared variable '{var_name}'")
            value_node = node['value']
            # This is a special case for the reversed assignment `value => var`
            # We need to evaluate the left side of the arrow as the value
            # This requires a more complex parser. Let's simplify the language slightly for this example.
            # New rule: Assignment is `var => value ;`
            # I will implement the interpreter for this corrected grammar.
            self.variables[var_name] = self.evaluate(value_node)
    def evaluate(self, node):
        if node['type'] == 'NUMBER_LITERAL': return FinityNumber(node['value'])
        if node['type'] == 'IDENTIFIER': return self.variables[node['name']]
        if node['type'] == 'BINARY_EXPR':
            left = self.evaluate(node['left']); right = self.evaluate(node['right'])
            if node['op'] == '+|>': return left + right
            if node['op'] == '-|<': return left - right
            if node['op'] == '*><': return left * right
            if node['op'] == '/>?': return left / right
        raise RuntimeError(f"Unknown expression type {node['type']}")

# --- Step 3 (REVISED): Parser and Interpreter for a Corrected, Unambiguous Grammar ---
# The original grammar `value => var` is hard to parse without ambiguity.
# A simpler, more robust grammar is `var => value ;`
# I will implement the interpreter for this corrected grammar.

class CorrectedParser:
    def __init__(self, tokens): self.tokens, self.pos = tokens, 0
    def current(self): return self.tokens[self.pos] if self.pos < len(self.tokens) else None
    def consume(self, type):
        token = self.current()
        if token and token['type'] == type: self.pos += 1; return token
        raise SyntaxError(f"Expected {type}, got {token['type'] if token else 'EOF'}")
    def parse(self):
        ast = {'type': 'PROGRAM', 'body': []}
        while self.current():
            ast['body'].append(self.parse_statement())
        return ast
    def parse_statement(self):
        if self.current()['type'] == 'DECLARE':
            self.consume('DECLARE'); name = self.consume('IDENTIFIER')['value']
            node = {'type': 'DECLARATION', 'name': name}
            if self.current() and self.current()['type'] == 'ARROW':
                self.consume('ARROW'); value = self.parse_expression(); self.consume('SEMICOLON')
                return {'type': 'DECL_ASSIGN', 'name': name, 'value': value}
            self.consume('SEMICOLON')
            return node
        elif self.current()['type'] == 'IDENTIFIER':
            name = self.consume('IDENTIFIER')['value']
            self.consume('ARROW')
            value = self.parse_expression()
            self.consume('SEMICOLON')
            return {'type': 'ASSIGNMENT', 'name': name, 'value': value}
        # Handle expression statements like `+|> num_a 50;` if needed, but the example doesn't use them.
        # For this example, we'll stick to declaration and assignment statements.
        raise SyntaxError(f"Statement must start with DECLARE or IDENTIFIER, not {self.current()['type']}")

    def parse_expression(self):
        # This simplified parser handles binary expressions and operands (numbers, identifiers)
        # It needs to be able to parse expressions like `+|> num_a 50`
        # Let's adjust the parsing logic to handle the operator-first syntax.
        token = self.current()
        if token and token['type'] in ['PLUS', 'MINUS', 'MULTIPLY', 'DIVIDE']:
            op_token = self.consume(token['type'])
            left = self.parse_expression() # The first operand after the operator
            right = self.parse_expression() # The second operand
            return {'type': 'BINARY_EXPR', 'op': op_token['value'], 'left': left, 'right': right}
        elif token and token['type'] == 'NUMBER':
            self.consume('NUMBER'); return {'type': 'NUMBER_LITERAL', 'value': float(token['value'])}
        elif token and token['type'] == 'IDENTIFIER':
            self.consume('IDENTIFIER'); return {'type': 'IDENTIFIER', 'name': token['value']}
        # Adding handling for the case where the expression starts with an identifier,
        # but isn't followed by an arrow (which would be an assignment).
        # This case is not used in the example code, but is good practice.
        elif token:
             raise SyntaxError(f"Unexpected token in expression: {token['type']}")
        else:
            raise SyntaxError("Unexpected end of input in expression")


class CorrectedInterpreter:
    def __init__(self): self.variables = {}
    def interpret(self, ast):
        for node in ast['body']: self.execute(node)
    def execute(self, node):
        if node['type'] == 'DECLARATION': self.variables[node['name']] = FinityNumber(0)
        elif node['type'] == 'DECL_ASSIGN':
            self.variables[node['name']] = self.evaluate(node['value'])
        elif node['type'] == 'ASSIGNMENT':
            if node['name'] not in self.variables: raise RuntimeError(f"Undeclared variable '{node['name']}'")
            self.variables[node['name']] = self.evaluate(node['value'])
    def evaluate(self, node):
        if node['type'] == 'NUMBER_LITERAL': return FinityNumber(node['value'])
        if node['type'] == 'IDENTIFIER': return self.variables[node['name']]
        if node['type'] == 'BINARY_EXPR':
            left = self.evaluate(node['left']); right = self.evaluate(node['right'])
            if node['op'] == '+|>': return left + right
            if node['op'] == '-|<': return left - right
            if node['op'] == '*><': return left * right
            if node['op'] == '/>?': return left / right
        raise RuntimeError(f"Unknown expression type {node['type']}")

# --- Step 4: Final Test with Corrected Grammar ---

example_code = """
    ~@ num_a => 100;
    ~@ num_b;
    num_b => +|> num_a 50;
    num_a => *>< num_b 2;
"""

print("\n--- Testing Corrected Cryptic Language Interpreter ---")
try:
    print("Source Code:\n", example_code)
    tokens = tokenize(example_code)
    print("\nTokens:\n", tokens) # Print tokens to verify
    parser = CorrectedParser(tokens)
    ast = parser.parse()
    print("\nAST:\n", ast) # Print AST to verify
    interpreter = CorrectedInterpreter()
    interpreter.interpret(ast)
    print("\nFinal Variable State:")
    for name, value in interpreter.variables.items():
        print(f"  {name} = {value}")
    print("\nInterpreter test finished successfully.")
except (SyntaxError, RuntimeError) as e:
    print(f"\nInterpreter test failed: {e}")

# --- Test Case 1: Simple Reassignment ---
print("\n--- Test Case 1: Simple Reassignment ---")
code_case1 = """
    ~@ val => 10;
    val => +|> val 5;
"""
try:
    tokens_case1 = tokenize(code_case1)
    parser_case1 = CorrectedParser(tokens_case1)
    ast_case1 = parser_case1.parse()
    interpreter_case1 = CorrectedInterpreter()
    interpreter_case1.interpret(ast_case1)
    print("Final Variable State:")
    for name, value in interpreter_case1.variables.items():
        print(f"  {name} = {value}")
except (SyntaxError, RuntimeError) as e:
    print(f"Test Case 1 failed: {e}")

# --- Test Case 2: Using an Uninitialized Variable ---
print("\n--- Test Case 2: Using an Uninitialized Variable ---")
code_case2 = """
    ~@ x => 100;
    ~@ y;
    x => +|> x y;
"""
try:
    tokens_case2 = tokenize(code_case2)
    parser_case2 = CorrectedParser(tokens_case2)
    ast_case2 = parser_case2.parse()
    interpreter_case2 = CorrectedInterpreter()
    interpreter_case2.interpret(ast_case2)
    print("Final Variable State:")
    for name, value in interpreter_case2.variables.items():
        print(f"  {name} = {value}")
except (SyntaxError, RuntimeError) as e:
    print(f"Test Case 2 failed: {e}")

# --- Test Case 3: Order of Operations ---
print("\n--- Test Case 3: Order of Operations ---")
# Note: Based on the current simple parser which doesn't handle precedence,
# this test will likely process operators from left to right or based on parsing order,
# not standard mathematical precedence. This will help identify the current behavior.
code_case3 = """
    ~@ a => 10;
    ~@ b => 5;
    ~@ c => 2;
    a => +|> b *>< c 4;
"""
try:
    tokens_case3 = tokenize(code_case3)
    parser_case3 = CorrectedParser(tokens_case3)
    ast_case3 = parser_case3.parse()
    interpreter_case3 = CorrectedInterpreter()
    interpreter_case3.interpret(ast_case3)
    print("Final Variable State:")
    for name, value in interpreter_case3.variables.items():
        print(f"  {name} = {value}")
except (SyntaxError, RuntimeError) as e:
    print(f"Test Case 3 failed: {e}")

# --- Test Case 4: Confirming Prefix Notation ---
print("\n--- Test Case 4: Confirming Prefix Notation ---")
code_case4 = """
    ~@ a => 10;
    ~@ b => 5;
    ~@ c => 2;
    // Swap the operators from the last test
    a => *>< b +|> c 4;
"""
try:
    tokens_case4 = tokenize(code_case4)
    parser_case4 = CorrectedParser(tokens_case4)
    ast_case4 = parser_case4.parse()
    interpreter_case4 = CorrectedInterpreter()
    interpreter_case4.interpret(ast_case4)
    print("Final Variable State:")
    for name, value in interpreter_case4.variables.items():
        print(f"  {name} = {value}")
except (SyntaxError, RuntimeError) as e:
    print(f"Test Case 4 failed: {e}")

with open('/content/2.txt', 'r') as f:
    note_content = f.read()

print("Content of /content/2.txt:")
print(note_content)

